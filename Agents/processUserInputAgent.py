import sys
from pathlib import Path
import json

# Add root project directory to sys.path
sys.path.append(str(Path(__file__).resolve().parent.parent))



from typing import Dict, List, Optional, Any, TypedDict, Annotated, Union
from datetime import datetime

from utilities.modelRelated import invoke_model, invoke_model_with_tools
from utilities.processFiles import detect_and_process_file_paths, store_uploaded_files

from pathlib import Path
# Create an interactive chatbox using gradio
import gradio as gr
from dotenv import load_dotenv


from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
# from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, interrupt
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool


class ProcessUserInputState(TypedDict):
    message: Annotated[List[BaseMessage], add_messages]
    user_input: str
    user_uploaded_files: List[str]
    text_input_validation: str
    previous_messages: List[BaseMessage]





class ProcessUserInputAgent:

    def __init__(self):
        self.memory = MemorySaver()
        self.graph = self._build_graph(self.memory)


    def _create_initial_state(self, session_id: str, previous_messages: List[BaseMessage]) -> ProcessUserInputState:
        return {
            "session_id": session_id,
            "previous_messages": previous_messages,
            "user_input": "",
            "user_uploaded_files": [],
            "text_input_validation": "",
        }
    

    def _build_graph(self, memory):
        graph = StateGraph(ProcessUserInputState)
        graph.add_node("collect_user_input", self._collect_user_input)
        graph.add_node("analyze_user_input_text", self._analyze_user_input_text)
    
        graph.add_edge(START, "collect_user_input")
        graph.add_conditional_edges("collect_user_input", self._route_after_collect_user_input)
        graph.add_edge("analyze_user_input_text", END)

        return graph.compile(memory)

    def _collect_user_input(self, state: ProcessUserInputState) -> ProcessUserInputState:
        """æ”¶é›†ç”¨æˆ·ä¿¡æ¯"""
        print("\nğŸ” å¼€å§‹æ‰§è¡Œ: _collect_user_input")
        print("=" * 50)
        print("âŒ¨ï¸ ç­‰å¾…ç”¨æˆ·è¾“å…¥...")


        user_input = interrupt("è¯·è¾“å…¥ç”¨æˆ·ä¿¡æ¯")
        detcted_files = detect_and_process_file_paths(user_input)
        if detcted_files:
            print(f"ğŸ“‚ æ£€æµ‹åˆ°ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶: {detcted_files}")
            stored_files = store_uploaded_files(detcted_files, state["session_id"])
            state["user_uploaded_files"] = stored_files



        print(f"ğŸ“¥ æ¥æ”¶åˆ°ç”¨æˆ·è¾“å…¥: {user_input[:100]}{'...' if len(user_input) > 100 else ''}")
        print("âœ… _collect_user_input æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        

        return {"user_input": user_input}
    


    def _route_after_collect_user_input(self, state: ProcessUserInputState) -> ProcessUserInputState:
        if state["user_uploaded_files"]:
            return "process_uploaded_files"
        else:
            return "analyze_user_input_text"



    def _analyze_user_input_text(self, state: ProcessUserInputState) -> ProcessUserInputState:
        """This node performs a safety check on user text input when all uploaded files are irrelevant.
        It validates if the user input contains meaningful table/Excel-related content.
        Returns [Valid] or [Invalid] based on the analysis."""
        
        print("\nğŸ” å¼€å§‹æ‰§è¡Œ: _analyze_user_input_text")
        print("=" * 50)
        
        user_input = state["user_input"]
        print(f"ğŸ“ æ­£åœ¨åˆ†æç”¨æˆ·æ–‡æœ¬è¾“å…¥: {user_input[:100]}{'...' if len(user_input) > 100 else ''}")
        
        if not user_input or user_input.strip() == "":
            print("âŒ ç”¨æˆ·è¾“å…¥ä¸ºç©º")
            print("âœ… _analyze_text_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            return {
                "text_input_validation": "[Invalid]",
                "process_user_input_messages": [SystemMessage(content="âŒ ç”¨æˆ·è¾“å…¥ä¸ºç©ºï¼ŒéªŒè¯å¤±è´¥")]
            }
        
        # Create validation prompt for text input safety check
        # Get the previous AI message content safely
        previous_ai_content = ""
        try:
            if state.get("previous_AI_messages"):
                previous_ai_messages = state["previous_AI_messages"]
                print(f"ğŸ” previous_AI_messages ç±»å‹: {type(previous_ai_messages)}")
                
                # Handle both single message and list of messages
                if isinstance(previous_ai_messages, list):
                    if len(previous_ai_messages) > 0:
                        latest_message = previous_ai_messages[-1]
                        if hasattr(latest_message, 'content'):
                            previous_ai_content = latest_message.content
                        else:
                            previous_ai_content = str(latest_message)
                        print(f"ğŸ“ ä»æ¶ˆæ¯åˆ—è¡¨æå–å†…å®¹ï¼Œé•¿åº¦: {len(previous_ai_content)}")
                    else:
                        print("âš ï¸ æ¶ˆæ¯åˆ—è¡¨ä¸ºç©º")
                else:
                    # It's a single message object
                    if hasattr(previous_ai_messages, 'content'):
                        previous_ai_content = previous_ai_messages.content
                    else:
                        previous_ai_content = str(previous_ai_messages)
                    print(f"ğŸ“ ä»å•ä¸ªæ¶ˆæ¯æå–å†…å®¹ï¼Œé•¿åº¦: {len(previous_ai_content)}")
            else:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°previous_AI_messages")
                
        except Exception as e:
            print(f"âŒ æå–previous_AI_messageså†…å®¹æ—¶å‡ºé”™: {e}")
            previous_ai_content = ""
            
        print(f"ä¸Šä¸€è½®aiè¾“å…¥å†…å®¹ï¼š=========================================\n{previous_ai_content}")
        system_prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¾“å…¥éªŒè¯ä¸“å®¶ï¼Œä»»åŠ¡æ˜¯åˆ¤æ–­ç”¨æˆ·çš„æ–‡æœ¬è¾“å…¥æ˜¯å¦ä¸**è¡¨æ ¼ç”Ÿæˆæˆ– Excel å¤„ç†ç›¸å…³**ï¼Œå¹¶ä¸”æ˜¯å¦åœ¨å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ä¸­å…·æœ‰å®é™…æ„ä¹‰ã€‚

ä½ å°†è·å¾—ä»¥ä¸‹ä¸¤éƒ¨åˆ†ä¿¡æ¯ï¼š
- ä¸Šä¸€è½® AI çš„å›å¤ï¼ˆç”¨äºåˆ¤æ–­ä¸Šä¸‹æ–‡æ˜¯å¦è¿è´¯ï¼‰
- å½“å‰ç”¨æˆ·çš„è¾“å…¥å†…å®¹

è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†è¿›è¡Œåˆ¤æ–­ï¼š

ã€æœ‰æ•ˆè¾“å…¥ [Valid]ã€‘æ»¡è¶³ä»¥ä¸‹ä»»ä¸€æ¡ä»¶å³å¯è§†ä¸ºæœ‰æ•ˆï¼š
- æ˜ç¡®æåˆ°ç”Ÿæˆè¡¨æ ¼ã€å¡«å†™è¡¨æ ¼ã€Excel å¤„ç†ã€æ•°æ®æ•´ç†ç­‰ç›¸å…³æ“ä½œ
- æå‡ºå…³äºè¡¨æ ¼å­—æ®µã€æ•°æ®æ ¼å¼ã€æ¨¡æ¿ç»“æ„ç­‰æ–¹é¢çš„éœ€æ±‚æˆ–æé—®
- æä¾›è¡¨æ ¼ç›¸å…³çš„æ•°æ®å†…å®¹ã€å­—æ®µè¯´æ˜æˆ–è§„åˆ™
- å¯¹ä¸Šä¸€è½® AI çš„å›å¤ä½œå‡ºæœ‰æ„ä¹‰çš„å»¶ç»­æˆ–å›åº”ï¼ˆå³ä½¿æœªç›´æ¥æåˆ°è¡¨æ ¼ï¼‰
- å³ä½¿å­˜åœ¨é”™åˆ«å­—ã€è¯­ç—…ã€æ‹¼å†™é”™è¯¯ï¼Œåªè¦è¯­ä¹‰æ¸…æ™°åˆç†ï¼Œä¹Ÿè§†ä¸ºæœ‰æ•ˆ

ã€æ— æ•ˆè¾“å…¥ [Invalid]ã€‘ç¬¦åˆä»¥ä¸‹ä»»ä¸€æƒ…å†µå³è§†ä¸ºæ— æ•ˆï¼š
- å†…å®¹ä¸è¡¨æ ¼/Excel å®Œå…¨æ— å…³ï¼ˆå¦‚é—²èŠã€æƒ…ç»ªè¡¨è¾¾ã€ä¸ä¸Šä¸‹æ–‡è·³è„±ï¼‰
- æ˜æ˜¾ä¸ºæµ‹è¯•æ–‡æœ¬ã€éšæœºå­—ç¬¦æˆ–ç³»ç»Ÿè°ƒè¯•è¾“å…¥ï¼ˆå¦‚ "123"ã€"æµ‹è¯•ä¸€ä¸‹"ã€"å“ˆå•Šå•Šå•Š" ç­‰ï¼‰
- ä»…åŒ…å«ç©ºç™½ã€è¡¨æƒ…ç¬¦å·ã€æ ‡ç‚¹ç¬¦å·ç­‰æ— å®é™…å†…å®¹

ã€è¾“å‡ºè¦æ±‚ã€‘
è¯·ä½ æ ¹æ®ä¸Šè¿°æ ‡å‡†ï¼Œ**ä»…è¾“å‡ºä»¥ä¸‹ä¸¤ç§ç»“æœä¹‹ä¸€**ï¼ˆä¸æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼‰ï¼š
- [Valid]
- [Invalid]

ã€ä¸Šä¸€è½® AI çš„å›å¤ã€‘
{previous_ai_content}
"""



        
        try:
            print("ğŸ“¤ æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œæ–‡æœ¬è¾“å…¥éªŒè¯...")
            # Get LLM validation
            user_input = "ç”¨æˆ·è¾“å…¥ï¼š" + user_input
            print("analyze_text_inputæ—¶è°ƒç”¨æ¨¡å‹çš„è¾“å…¥: \n" + user_input)              
            validation_response = invoke_model(model_name="Pro/deepseek-ai/DeepSeek-V3", messages=[SystemMessage(content=system_prompt), HumanMessage(content=user_input)])
            # validation_response = self.llm_s.invoke([SystemMessage(content=system_prompt)])
            
            print(f"ğŸ“¥ éªŒè¯å“åº”: {validation_response}")
            
            if "[Valid]" in validation_response:
                validation_result = "[Valid]"
                status_message = "ç”¨æˆ·è¾“å…¥éªŒè¯é€šè¿‡ - å†…å®¹ä¸è¡¨æ ¼ç›¸å…³ä¸”æœ‰æ„ä¹‰"
            elif "[Invalid]" in validation_response:
                validation_result = "[Invalid]"
                status_message = "ç”¨æˆ·è¾“å…¥éªŒè¯å¤±è´¥ - å†…å®¹ä¸è¡¨æ ¼æ— å…³æˆ–æ— æ„ä¹‰"
            else:
                # Default to Invalid for safety
                validation_result = "[Invalid]"
                status_message = "ç”¨æˆ·è¾“å…¥éªŒè¯å¤±è´¥ - æ— æ³•ç¡®å®šè¾“å…¥æœ‰æ•ˆæ€§ï¼Œé»˜è®¤ä¸ºæ— æ•ˆ"
                print(f"âš ï¸ æ— æ³•è§£æéªŒè¯ç»“æœï¼ŒLLMå“åº”: {validation_response}")
            
            print(f"ğŸ“Š éªŒè¯ç»“æœ: {validation_result}")
            print(f"ğŸ“‹ çŠ¶æ€è¯´æ˜: {status_message}")
            
            # Create validation summary
            summary_message = f"""æ–‡æœ¬è¾“å…¥å®‰å…¨æ£€æŸ¥å®Œæˆ:
            
            **ç”¨æˆ·è¾“å…¥**: {user_input[:100]}{'...' if len(user_input) > 100 else ''}
            **éªŒè¯ç»“æœ**: {validation_result}
            **çŠ¶æ€**: {status_message}"""
            
            print("âœ… _analyze_text_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            
            return {
                "text_input_validation": validation_result,
                "messages": [SystemMessage(content=summary_message)]
            }
                
        except Exception as e:
            print(f"âŒ éªŒè¯æ–‡æœ¬è¾“å…¥æ—¶å‡ºé”™: {e}")
            
            # Default to Invalid for safety when there's an error
            error_message = f"""âŒ æ–‡æœ¬è¾“å…¥éªŒè¯å‡ºé”™: {e}
            
            ğŸ“„ **ç”¨æˆ·è¾“å…¥**: {user_input[:100]}{'...' if len(user_input) > 100 else ''}
            ğŸ”’ **å®‰å…¨æªæ–½**: é»˜è®¤æ ‡è®°ä¸ºæ— æ•ˆè¾“å…¥"""
            
            print("âœ… _analyze_text_input æ‰§è¡Œå®Œæˆ (å‡ºé”™)")
            print("=" * 50)
            
            return {
                "text_input_validation": "[Invalid]",
                "process_user_input_messages": [SystemMessage(content=error_message)]
            }

    def _route_after_analyze_user_input_text(self, state: ProcessUserInputState) -> ProcessUserInputState:
        if state["text_input_validation"] == "[Valid]":
            return END
        else:
            return "collect_user_input"

    def run_process_user_input(self, session_id: str, previous_messages: List[BaseMessage]) -> ProcessUserInputState:
        """è¿è¡Œç”¨æˆ·è¾“å…¥å¤„ç†æµç¨‹"""
        print("\nğŸš€ å¼€å§‹è¿è¡Œ ProcessUserInputAgent")
        print("=" * 60)

        inital_state = self._create_initial_state(session_id, previous_messages)
        config = {"configurable": {"thread_id": session_id}}

        print(f"ğŸ“‹ ä¼šè¯ID: {session_id}")
        print(f"ğŸ“ åˆå§‹çŠ¶æ€å·²åˆ›å»º")
        print("ğŸ”„ æ­£åœ¨æ‰§è¡Œç”¨æˆ·è¾“å…¥å¤„ç†å·¥ä½œæµ...")
        try:
            while True:
                finial_state =  self.graph.invoke(inital_state, config )
                if "__interrupted__" in finial_state:
                    interrupt_value = finial_state["__interrupted__"][0].value
                    print(f"ğŸ’¬ æ™ºèƒ½ä½“: {interrupt_value}")
                    user_response = input("è¯·è¾“å…¥ç”¨æˆ·å“åº”: ")
                    inital_state = Command(resume=user_response)
                    continue

                print("ğŸ‰æ‰§è¡Œå®Œæ¯•")
                return finial_state
            
        except Exception as e:
            print(f"âŒ è¿è¡Œç”¨æˆ·è¾“å…¥å¤„ç†æµç¨‹æ—¶å‡ºé”™: {e}")

            return None
        
    

        
        
        
        
    
    

